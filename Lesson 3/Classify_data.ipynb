{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classify_data.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CUUZRe0Xr-I5","colab_type":"code","outputId":"b60033c5-c653-4a1b-c167-e6a7eac1ba9e","executionInfo":{"status":"ok","timestamp":1562840123730,"user_tz":-420,"elapsed":27360,"user":{"displayName":"Mar Heaven","photoUrl":"https://lh4.googleusercontent.com/-yP3GNUgefoI/AAAAAAAAAAI/AAAAAAAAABc/BTjJt5MEJz0/s64/photo.jpg","userId":"09945430610895316219"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e52lH650xW8J","colab_type":"code","outputId":"c5be576c-da85-4f49-9d24-7a8f7b934682","executionInfo":{"status":"ok","timestamp":1562840130533,"user_tz":-420,"elapsed":5001,"user":{"displayName":"Mar Heaven","photoUrl":"https://lh4.googleusercontent.com/-yP3GNUgefoI/AAAAAAAAAAI/AAAAAAAAABc/BTjJt5MEJz0/s64/photo.jpg","userId":"09945430610895316219"}},"colab":{"base_uri":"https://localhost:8080/","height":331}},"source":["!pip install gensim"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.4)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.4)\n","Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.180)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.180 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.180)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.6.16)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n","Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.180->boto3->smart-open>=1.2.1->gensim) (0.14)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.180->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RqTmlw5NtNCs","colab_type":"text"},"source":["READ FILE AND ENGINEERRING FEATURE"]},{"cell_type":"code","metadata":{"id":"_-ncYospw-pN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1356decd-c800-45fe-8547-e71ab5f409f0","executionInfo":{"status":"ok","timestamp":1562840136805,"user_tz":-420,"elapsed":2952,"user":{"displayName":"Mar Heaven","photoUrl":"https://lh4.googleusercontent.com/-yP3GNUgefoI/AAAAAAAAAAI/AAAAAAAAABc/BTjJt5MEJz0/s64/photo.jpg","userId":"09945430610895316219"}}},"source":["import numpy as np\n","import gensim as gs\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","import keras.models\n","from keras.models import Sequential\n","from keras.layers import Activation, Dense, Dropout\n","from sklearn.model_selection import cross_val_score, GridSearchCV\n","from sklearn.svm import SVC\n","import re\n","import csv\n","\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"SpxafM-8p9J7","colab_type":"code","colab":{}},"source":["def pre_process(text):\n","    text = text.lower()\n","    # remove tags\n","    text = re.sub(\"<!--?.*?-->\", \"\", text)\n","    # remove special characters and digits\n","    text = re.sub(\"(\\\\d|\\\\W)+\", \" \", text)\n","    return text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"APRxB9F1N5_w","colab_type":"code","colab":{}},"source":["\n","def read_data(filename):\n","    file = []\n","    with open(filename,encoding=\"utf8\") as fp:\n","        line = fp.readline()\n","        line =  pre_process(line)\n","        line = gs.utils.simple_preprocess(line)\n","\n","\n","        while line:\n","           file.append(line)\n","           line = fp.readline()\n","           line =  pre_process(line)\n","           line = gs.utils.simple_preprocess(line)\n","    file = np.reshape(file, (len(file),1))\n","    fp.close()\n","    return file\n","\n","def load_train_data(filepath, minidx, maxidx):\n","    filename = filepath + str(minidx) +'.txt'\n","    file = read_data(filename)\n","    data = np.array(file)\n","    for i in range(minidx +1 , maxidx +1 ):\n","        filename = filepath + str(i) +'.txt'\n","        file = read_data(filename)\n","        data = np.concatenate((data,file), axis=0)\n","\n","    labels = []\n","    for i in range(minidx, maxidx +1):\n","        labels += [i]*2000\n","\n","    return data, labels\n","\n","\n","def load_test_data(filepath):\n","    filename_1 = filepath +  'data.txt'\n","    file = read_data(filename_1)\n","    data = np.array(file)\n","\n","    filename_2 = filepath + 'label.txt'\n","    with open(filename_2) as f:\n","        labels = []\n","        for line in f:\n","            labels.append(int(line))\n","\n","    f.close()\n","    labels = np.array(labels)\n","    return data, labels\n","  \n","def one_hot_coding(Y,num_class):\n","    Y_one_hot_code = np.zeros((len(Y),num_class))\n","    for i in np.arange(len(Y)):\n","        Y_one_hot_code[i][Y[i]-1] = 1\n","    return Y_one_hot_code    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WrPFhso-OcPD","colab_type":"text"},"source":["USING COUNT VECTORIZER"]},{"cell_type":"code","metadata":{"id":"WANTsprwswBc","colab_type":"code","colab":{}},"source":["def feature_engineering(data_train, data_test):\n","    X_train = []\n","    for i in np.arange(data_train.shape[0]):\n","        data_i = data_train[i]\n","        doc_i = ''\n","        for i in np.arange(len(data_i[0])):\n","            doc_i += data_i[0][i]\n","            doc_i += ' '\n","        X_train.append(doc_i)\n","\n","    X_test = []\n","    for i in np.arange(data_test.shape[0]):\n","        data_i = data_test[i]\n","        doc_i = ''\n","        for i in np.arange(len(data_i[0])):\n","            doc_i += data_i[0][i]\n","            doc_i += ' '\n","        X_test.append(doc_i)\n","\n","    count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n","    count_vect.fit(X_train)\n","    X_train = count_vect.transform(X_train)\n","    X_test  = count_vect.transform(X_test)\n","    return X_train, X_test "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6bBVKoqGFlKW","colab_type":"code","outputId":"7bb87c02-84c5-4115-9702-e08ab762edf2","executionInfo":{"status":"ok","timestamp":1562576197618,"user_tz":-420,"elapsed":52943,"user":{"displayName":"Mar Heaven","photoUrl":"https://lh4.googleusercontent.com/-yP3GNUgefoI/AAAAAAAAAAI/AAAAAAAAABc/BTjJt5MEJz0/s64/photo.jpg","userId":"09945430610895316219"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["data_train, labels_train = load_train_data('/content/drive/My Drive/Intership/classify_data/train/', 1, 13)\n","data_test, labels_test = load_test_data('/content/drive/My Drive/Intership/classify_data/test/')\n","X_train, X_test = feature_engineering(data_train,data_test)\n","\n","# print(data_train)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(26000, 79775)\n","(6500, 79775)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fSbOgXcfhiig","colab_type":"code","colab":{}},"source":["with open('people.csv', 'w') as writeFile:\n","    writer = csv.writer(writeFile)\n","    writer.writerows(lines)\n","\n","writeFile.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lLDrMXXotH1e","colab_type":"text"},"source":["CLASSIFICATION WITH DNN"]},{"cell_type":"code","metadata":{"id":"LAg2sc5QOLka","colab_type":"code","colab":{}},"source":["def baseline_model(X, y ):\n","  input_dim = X.shape[1]\n","  print(input_dim)\n","  model = Sequential()\n","  model.add(Dense(units=1024, activation='relu', input_dim=input_dim, name =\"Input\"))\n","  model.add(Dropout(0.3))\n","  model.add(Dense(units=512, activation='relu'))\n","  model.add(Dropout(0.3))\n","  model.add(Dense(units=13, activation='softmax'))\n","\t# Compile model\n","  model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy']) \n","  model.fit(X, y, epochs = 10, batch_size = 1000)\n","\n","  return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmNWKtySsybd","colab_type":"code","outputId":"8d8aba30-5069-423d-de93-64c3b3c4a843","executionInfo":{"status":"ok","timestamp":1562576435246,"user_tz":-420,"elapsed":132152,"user":{"displayName":"Mar Heaven","photoUrl":"https://lh4.googleusercontent.com/-yP3GNUgefoI/AAAAAAAAAAI/AAAAAAAAABc/BTjJt5MEJz0/s64/photo.jpg","userId":"09945430610895316219"}},"colab":{"base_uri":"https://localhost:8080/","height":543}},"source":["if __name__  == '__main__':\n","    labels_train = np.array(labels_train)\n","    labels_test   = np.array(labels_test)\n","    num_class = 13\n","    labels_train = one_hot_coding(labels_train, num_class)\n","    labels_test  = one_hot_coding(labels_test, num_class)\n","    print(labels_train)\n","    model = baseline_model(X_train, labels_train)\n","    scores = model.evaluate(X_test, labels_test)\n","    print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[1. 0. 0. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 1.]]\n","79775\n","Epoch 1/10\n","26000/26000 [==============================] - 14s 556us/step - loss: 0.7897 - acc: 0.7857\n","Epoch 2/10\n","26000/26000 [==============================] - 13s 482us/step - loss: 0.2225 - acc: 0.9388\n","Epoch 3/10\n","26000/26000 [==============================] - 13s 482us/step - loss: 0.1173 - acc: 0.9701\n","Epoch 4/10\n","26000/26000 [==============================] - 13s 484us/step - loss: 0.0869 - acc: 0.9786\n","Epoch 5/10\n","26000/26000 [==============================] - 13s 484us/step - loss: 0.0747 - acc: 0.9820\n","Epoch 6/10\n","26000/26000 [==============================] - 13s 485us/step - loss: 0.0647 - acc: 0.9842\n","Epoch 7/10\n","26000/26000 [==============================] - 13s 487us/step - loss: 0.0616 - acc: 0.9858\n","Epoch 8/10\n","26000/26000 [==============================] - 13s 483us/step - loss: 0.0570 - acc: 0.9867\n","Epoch 9/10\n","26000/26000 [==============================] - 13s 482us/step - loss: 0.0544 - acc: 0.9871\n","Epoch 10/10\n","26000/26000 [==============================] - 13s 486us/step - loss: 0.0497 - acc: 0.9876\n","6500/6500 [==============================] - 3s 493us/step\n","\n","acc: 88.58%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qeugCBV1tDle","colab_type":"text"},"source":["IMPLEMENT SVM WITH LIBRARY"]},{"cell_type":"code","metadata":{"id":"DsTJeq8ZAMAF","colab_type":"code","outputId":"6bf88170-5857-47af-8f56-e8a7b50c6d4d","executionInfo":{"status":"ok","timestamp":1561965280566,"user_tz":-420,"elapsed":22103595,"user":{"displayName":"Mar Heaven","photoUrl":"https://lh4.googleusercontent.com/-yP3GNUgefoI/AAAAAAAAAAI/AAAAAAAAABc/BTjJt5MEJz0/s64/photo.jpg","userId":"09945430610895316219"}},"colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}, {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n","svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n","svm_model.fit(X_train, labels_train)\n","print('Best score for training data:', svm_model.best_score_,\"\\n\") \n","print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n","print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n","print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Best score for training data: 0.8372692307692308 \n","\n","Best C: 100 \n","\n","Best Kernel: rbf \n","\n","Best Gamma: 0.0001 \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dNQOJTr5Fiv2","colab_type":"code","outputId":"ca98cfa9-0523-40da-a817-1e77c1ef6fe0","executionInfo":{"status":"ok","timestamp":1562037784168,"user_tz":-420,"elapsed":349412,"user":{"displayName":"Mar Heaven","photoUrl":"https://lh4.googleusercontent.com/-yP3GNUgefoI/AAAAAAAAAAI/AAAAAAAAABc/BTjJt5MEJz0/s64/photo.jpg","userId":"09945430610895316219"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["if __name__  == '__main__':\n","    y_train = np.array(labels_train)\n","    y_test   = np.array(labels_test)\n","    num_class = 13\n","#     labels_train = one_hot_coding(labels_train, num_class)\n","#     labels_test  = one_hot_coding(labels_test, num_class)\n","    svm_model = SVC(kernel=\"rbf\",gamma = 0.0001,  C=100).fit(X_train, y_train)\n","    score = svm_model.score(X_test, y_test)\n","    print(\"\\n %.2f%%\" % (score*100))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n"," 87.62%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7bPasi9ms8dc","colab_type":"text"},"source":["IMPLEMENT SVM WITH NUMPY\n"]},{"cell_type":"code","metadata":{"id":"y7zzNPYzs7Ca","colab_type":"code","colab":{}},"source":["def  computed_dW(W,X,y,reg):\n","    d, C = W.shape;\n","    N = X.shape[0];\n","    loss = 0;\n","    dW = np.zeros((d,C))\n","    id0 = np.arange(N);\n","    Z = X.dot(W);\n","    correct_core =  Z[id0,y].reshape(N,1);\n","    margins = np.maximum(0, Z - correct_core +1);\n","    margins[id0,y] = 0;\n","    loss = np.sum(margins);\n","    loss /= N;\n","    loss += 0.5*reg*np.sum(W*W);\n","\n","    F = (margins>0).astype(int);\n","    id1 = np.arange(F.shape[0])\n","    F[id1,y] = np.sum(-F,axis=1);\n","    dW = X.T.dot(F)/N + reg*W;\n","    return loss, dW"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lNKRo_wY0Tab","colab_type":"code","colab":{}},"source":["def classify_svm(X,y, W, reg,lr =0.1, batch_size = 1000, epochs = 10):\n","    W =W;\n","    num_iters = int(X.shape[0]/batch_size)\n","    for epoch in np.arange(epochs):\n","      loss_history= [];\n","      print(\"Epochs : {}\".format(epoch + 1))\n","      X, y = shuffer_data(X,y)\n","      for it in np.arange(num_iters):\n","          start = it*batch_size\n","          end = (it+1)*batch_size\n","          X_batch = X[start:end];\n","          y_batch = y[start:end];\n","          loss, dW = computed_dW(W,X_batch,y_batch,reg)\n","          loss_history.append(loss);\n","          W -= lr*dW;\n","          if it% 200 ==0 :\n","              print('it %d/%d, loss = %f' %(it, num_iters, loss_history[it]));\n","    return W, loss_history\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Szp99A6nQPf_","colab_type":"code","colab":{}},"source":["def shuffer_data(X,y):\n","    N = X.shape[0]\n","    permutation = np.random.permutation(N)\n","    x_shuffer = X[permutation]\n","    y_shuffer = y[permutation]\n","    return x_shuffer, y_shuffer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kGp32Ohp0YN5","colab_type":"code","colab":{}},"source":["def predict(W,X):\n","    Z = X.dot(W);\n","    return np.argmax(Z,axis=1);\n","\n","def evaluate(W, X, y):\n","    y_pred = predict(W,X);\n","    acc = 100*np.mean(y_pred == y);\n","    return acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0pMXqPYt0eEa","colab_type":"code","outputId":"a8357baf-b086-4858-ee2e-186bb6eab007","executionInfo":{"status":"ok","timestamp":1562576272768,"user_tz":-420,"elapsed":21813,"user":{"displayName":"Mar Heaven","photoUrl":"https://lh4.googleusercontent.com/-yP3GNUgefoI/AAAAAAAAAAI/AAAAAAAAABc/BTjJt5MEJz0/s64/photo.jpg","userId":"09945430610895316219"}},"colab":{"base_uri":"https://localhost:8080/","height":305}},"source":["if __name__  == '__main__':\n","    y_train = np.array(labels_train)\n","    y_test   = np.array(labels_test)\n","    print(y_train.shape)\n","    y_train -= 1\n","    y_test   -= 1\n","    num_class = 13\n","  \n","    W_init = np.ones((X_train.shape[1],num_class))\n","    W, loss = classify_svm(X_train ,y_train, W_init, reg = 0.01 ,lr = 0.1, batch_size = 100, epochs =5)\n","    acc = evaluate(W, X_test, y_test)\n","    print(acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(26000,)\n","Epochs : 1\n","it 0/260, loss = 5197.375000\n","it 200/260, loss = 3476.968964\n","Epochs : 2\n","it 0/260, loss = 3083.260594\n","it 200/260, loss = 2066.689532\n","Epochs : 3\n","it 0/260, loss = 1832.945955\n","it 200/260, loss = 1228.509405\n","Epochs : 4\n","it 0/260, loss = 1089.608695\n","it 200/260, loss = 730.446069\n","Epochs : 5\n","it 0/260, loss = 648.034061\n","it 200/260, loss = 435.120187\n","74.43076923076923\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a_OwYKNu1gUH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}